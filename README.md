# DZ_SRE_4
**Chaos Testing SRE DZ 4**

Суть проводимого эксперимента убедиться в надежности системы, ее восстановлению, работе  в условиях высокой нагрузке и работе систем мониторинга и оповещения при этом

**1.	 Для начала произведем отключение  одного или нескольких узлов кластера etcd**
**А. При отключении узла etcd_node1 срабатывает  alert manager **
 ![ Alt 1](https://github.com/mnkozhin/DZ_SRE_4/blob/main/1.JPG)
Время срабатывания оповещения около 20 сек. При отключении происходит процесс выбора лидера patroni,  Он занимаем порядка 20-30 сек   после чего, кластер по прежнему работоспособен. 
Тоже самое происходит при отключении любого из трех узлов, при работающих двух
При отключении двух узлов из трёх, оставшийся узел переходит в режим блокировки, т.к. отсутствует кворумное большинство, и далее сервис становится неработоспособен, до восстановления узла или добавления нового 
![ Alt 1](https://github.com/mnkozhin/DZ_SRE_4/blob/main/2.JPG)
**Б. Отключение 1 из двух узлов PostgreSQL**
Время срабатывания оповещения около 20 сек.
Соответственно недоступность узла приводит к перевыбору лидера PostgreSQL 
![ Alt 1](https://github.com/mnkozhin/DZ_SRE_4/blob/main/2.JPG)
Сервис при этом работоспособен
при одновременном отключении обоих узлов сервис недоступен т.к. отсутствует соединение с БД

**2.	Нагрузка на узлы postgresql**
Во время теста на сервис будет производиться нагрузочное тестирование d 450 rps  с помощью jmeter для формирования фоновой нагрузки на сервис и контроля возникновения ошибок
Для формирования нагрузки будут последовательно использоваться следующие инструменты:
stress-ng —-cpu 0 --cpu-method matrixprod -t 60s
![ Alt 1](https://github.com/mnkozhin/DZ_SRE_4/blob/main/5.JPG)
![ Alt 1](https://github.com/mnkozhin/DZ_SRE_4/blob/main/6.JPG)
Нагрузка на ЦПУ matrixprod дает нужный микс операций с памятью, кэшем и плавающей запятой 
stress-ng --vm 9 --vm-bytes 90% -t 60s
 vm-bytes отлично подходит для стресс-тестов памяти. В этом примере stress-ng запускает 9 стресс-тестов виртуальной памяти, которые в час совокупно потребляют 90% доступной памяти. Т.о., каждый тресс-тест потребляет 10% доступной памяти.
 ![ Alt 1](https://github.com/mnkozhin/DZ_SRE_4/blob/main/7.JPG)
 ![ Alt 1](https://github.com/mnkozhin/DZ_SRE_4/blob/main/8.JPG)
stress-ng --iomix 1 --iomix-bytes 80% -t 60s
Нагрузка iomix-bytes пишет N-байты для каждого процесса-обработчика iomix; по умолчанию задан 1 Гб, и он идеален для выполнения стресс-теста вводы/вывода. В этом примере я задам 80% свободного места файловой системы.
![ Alt 1](https://github.com/mnkozhin/DZ_SRE_4/blob/main/9.JPG)
![ Alt 1](https://github.com/mnkozhin/DZ_SRE_4/blob/main/10.JPG)
**3.	Имитация частичной потери сети**
Во время теста на сервис будет производиться нагрузочное тестирование d 450 rps  с помощью jmeter для формирования фоновой нагрузки на сервис и контроля возникновения ошибок
Для формирования нагрузки будут последовательно использоваться следующие инструменты:

потеря 10% пакетов 

#Start
❯ sudo tc qdisc add dev ens160 root root netem corrupt 10%
#Stop
❯ sudo tc qdisc del dev ens160 root netem corrupt 10%

Запуск на обоих узлах кластера postgresql. По результату сета видна ~ 10% просадка rps, значительный рост latency до 400 мс q99

![ Alt 1](https://github.com/mnkozhin/DZ_SRE_4/blob/main/11.JPG)
Проверка с помощью ping  показывает значительный процент потери пакетов
![ Alt 1](https://github.com/mnkozhin/DZ_SRE_4/blob/main/12.JPG)
